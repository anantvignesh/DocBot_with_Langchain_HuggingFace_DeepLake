{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SHGZhPjaWElB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import langchain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
      ],
      "metadata": {
        "id": "785n1zwocRN9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
      ],
      "metadata": {
        "id": "KNiX8bVOZWpU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "OLvSbUJa3tnJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "#hf = HuggingFaceEmbeddings(model_name=model_name)"
      ],
      "metadata": {
        "id": "1be7vG_8n6-D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#flan = HuggingFaceHub(repo_id=\"google/flan-t5-large\")\n",
        "\n",
        "#flan_t5_xl=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", \n",
        "#                   model_kwargs={\"temperature\":0.5, \n",
        "#                                 \"min_length\":65, \n",
        "#                                 \"max_length\":128})\n",
        "\n",
        "gpt = OpenAI()"
      ],
      "metadata": {
        "id": "5iizTKj3oa17"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVdsi4Pp5cMh",
        "outputId": "f48b09b9-4b50-465e-f5ea-687c25fc00d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAI(cache=None, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7f043de6f9a0>, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.7, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load document\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/LLM/data/pdf/company-governance-corporate-governance-principles.pdf\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "Fz_ivrJvnnV6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the documents into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "36d-1cP4ooHt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select which embeddings we want to use\n",
        "#embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "xaMa1mNmopmf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the vectorestore to use as the index\n",
        "db = DeepLake.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSqvMWooorQ9",
        "outputId": "3fa7307a-89ec-41c6-d5d8-4574dff01bb9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mem://langchain loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 1/1 [00:05<00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='mem://langchain', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape     dtype  compression\n",
            "  -------   -------   -------   -------  ------- \n",
            " embedding  generic  (7, 1536)  float32   None   \n",
            "    ids      text     (7, 1)      str     None   \n",
            " metadata    json     (7, 1)      str     None   \n",
            "   text      text     (7, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# expose this index in a retriever interface\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})"
      ],
      "metadata": {
        "id": "KO6PcuhaovvM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a chain to answer questions \n",
        "qa = RetrievalQA.from_chain_type(llm=gpt, \n",
        "                                 chain_type=\"map_reduce\", \n",
        "                                 retriever=retriever, \n",
        "                                 return_source_documents=True)"
      ],
      "metadata": {
        "id": "C2aGgcV8oxBd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is selection process for directors?\"\n",
        "result = qa({\"query\": query})"
      ],
      "metadata": {
        "id": "gYN7Pd79o0Vs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)\n",
        "print(result['result'])"
      ],
      "metadata": {
        "id": "nA9dBvqNpm7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc73fe1-ea0a-492b-e220-1e457f51f463"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'what is selection process for directors?', 'result': ' The Board is responsible for its agenda and will establish a schedule of major discussion items for each year. The non-employee directors will meet without management present and a presiding director will be designated from time to time by the independent directors from among the independent directors to preside at such meetings. The presiding director will also serve as the presiding director in performing other functions as the Board may direct, including advising on the selection of committee chairs and advising the Chairman on the agenda for Board meetings.', 'source_documents': [Document(page_content='7 \\nV. Annual Performance Evaluation \\nThe Board and each of the Committees will perform an annual self-evaluation. Each of the directors will be requested to provide his or her assessment of the effectiveness of the Board and the Committees on which he or she serves. If determined by the Board to be desirable, the Board may retain independent corporate governance experts to assist the Board and the \\nCommittees with the self-evaluations. \\nMarch 2015', metadata={'source': '/content/drive/MyDrive/LLM/data/pdf/company-governance-corporate-governance-principles.pdf', 'page': 6}), Document(page_content=\"5 \\nThe Board and its Committees shall have the right at any time to retain independent \\noutside financial, legal or other advisors at Company expense. \\nIII. Meetings \\nThe Board of Directors ordinarily has 7 scheduled meetings a year. Directors ordinarily are \\nexpected to attend all scheduled Board and Committee meetings, the annual meeting of \\nshareholders, and are expected to review the materials provided to them in advance of each \\nmeeting. \\nThe Board shall be responsible for its agenda. Each year, the Chairman will propose for the \\nBoard's approval key issues of strategy, risk and corporate reputation to be scheduled and \\ndiscussed during the course of the year. The Board will be invited to offer its suggestions. \\nAs a result of this process, a schedule of major discussion items for the each year will be \\nestablished. \\nThe non-employee directors ordinarily will meet for a period of time at each regularly \\nscheduled Board meeting without management present. A presiding director, designated \\nfrom time to time by the independent directors from among the independent directors, will preside at such meetings, and also will serve as the presiding director in performing such other functions as the Board may direct, including advising on the selection of committee chairs and advising the Chairman on the agenda for Board meetings. The non-employee \\ndirectors may meet without management present at such other times as determined by the \\npresiding director or at the request of any non-employee director. \\nThe presiding director will, from time to time, and following consultation with the Chairs of \\nthe Committees of the Board and the other directors, discuss with the Chairman potential \\nitems for inclusion in the agendas of future meetings of the Board of Directors. \\nIV. Responsibilities and Duties \\nCEO/Management Oversight and Compensation \\nIn addition to the Board's general oversight of the CEO and senior management, the Board \\nalso is responsible for: \\n\\uf0b7 selecting, evaluating and compensating the CEO and overseeing CEO succession \\nplanning; \\n\\uf0b7 providing counsel and oversight on the selection, evaluation, development and compensation of the officers of the Company; and \\n\\uf0b7 approving and maintaining a succession plan for the CEO and other key senior executives, including an emergency succession plan for the CEO.\", metadata={'source': '/content/drive/MyDrive/LLM/data/pdf/company-governance-corporate-governance-principles.pdf', 'page': 4})]}\n",
            " The Board is responsible for its agenda and will establish a schedule of major discussion items for each year. The non-employee directors will meet without management present and a presiding director will be designated from time to time by the independent directors from among the independent directors to preside at such meetings. The presiding director will also serve as the presiding director in performing other functions as the Board may direct, including advising on the selection of committee chairs and advising the Chairman on the agenda for Board meetings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Board is responsible for its agenda and will establish a schedule of major discussion items for each year. The non-employee directors will meet without management present and a presiding director will be designated from time to time by the independent directors from among the independent directors to preside at such meetings. The presiding director will also serve as the presiding director in performing other functions as the Board may direct, including advising on the selection of committee chairs and advising the Chairman on the agenda for Board meetings."
      ],
      "metadata": {
        "id": "vH8jGs-X6Gur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ],
      "metadata": {
        "id": "Vn15zPWPmnWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flan = HuggingFaceHub(repo_id=\"google/flan-t5-small\")"
      ],
      "metadata": {
        "id": "JUM3O9FemCMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load document\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/LLM/data/pdf/company-governance-corporate-governance-principles.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "### For multiple documents \n",
        "# loaders = [....]\n",
        "# documents = []\n",
        "# for loader in loaders:\n",
        "#     documents.extend(loader.load())"
      ],
      "metadata": {
        "id": "IAAF6ZpclrYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm=OpenAI(), chain_type=\"map_reduce\")\n",
        "query = \"what is the total number of AI publications?\"\n",
        "chain.run(input_documents=documents, question=query)"
      ],
      "metadata": {
        "id": "LmOuh3e3iwnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DocBoT**"
      ],
      "metadata": {
        "id": "O8rMnrUA7wdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "ALcPry6p76Lz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceHubEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import PromptTemplate, HuggingFaceHub, LLMChain"
      ],
      "metadata": {
        "id": "Jks_XL1v89bk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ],
      "metadata": {
        "id": "sbHBu3R09DBf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "x3bnD0sc81zn"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select which embeddings we want to use\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "chatGPT = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=256)\n",
        "#print(llm(\"tell me a joke\"))"
      ],
      "metadata": {
        "id": "TD-UQuLF8OUQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatGPT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsAPMQI--gyU",
        "outputId": "ad01e03b-7c51-462d-ea8c-28e21d3fb82a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0x7f043de6f9a0>, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.5, model_kwargs={}, openai_api_key=None, openai_organization=None, request_timeout=60, max_retries=6, streaming=False, n=1, max_tokens=256)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load document\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/LLM/data/pdf/company-governance-corporate-governance-principles.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "# split the documents into chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# create the vectorestore to use as the index\n",
        "db = DeepLake.from_documents(texts, embeddings)\n",
        "\n",
        "# expose this index in a retriever interface\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvtNCilv8H4y",
        "outputId": "e0ddfec1-de27-4cb9-e05f-7c6134e1ab50"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mem://langchain loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 1/1 [00:04<00:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='mem://langchain', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape     dtype  compression\n",
            "  -------   -------   -------   -------  ------- \n",
            " embedding  generic  (7, 1536)  float32   None   \n",
            "    ids      text     (7, 1)      str     None   \n",
            " metadata    json     (7, 1)      str     None   \n",
            "   text      text     (7, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a chain to answer questions \n",
        "qa = ConversationalRetrievalChain.from_llm(chatGPT, retriever)"
      ],
      "metadata": {
        "id": "DbFLjT158R4o"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"what is selection process for directors?\"\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history})"
      ],
      "metadata": {
        "id": "kJbHkuOy8lCv"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okHUKcP3_g2R",
        "outputId": "a470a0f4-a161-4bf3-f16a-601173c3d247"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is selection process for directors?',\n",
              " 'chat_history': [],\n",
              " 'answer': 'Unfortunately, the given context does not provide information about the selection process for directors.'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igZ23IaQ_ies"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}